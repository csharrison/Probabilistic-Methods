\documentclass[12pt,letterpaper]{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{fullpage}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage[margin=3cm]{geometry}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}

% Edit these as appropriate
\newcommand\course{CS 155}
\newcommand\semester{Spring 2014}  % <-- current semester
\newcommand\asgnname{HW 6}         % <-- assignment name
\newcommand\yourname{Charles Harrison}  % <-- your name
\newcommand\login{csharris}          % <-- your CS login

\newenvironment{answer}[1]{
  \subsubsection*{Problem #1}
}{\newpage}

\pagestyle{fancyplain}
\headheight 35pt
\lhead{\yourname\ (\login)\\\course\ --- \semester}
\chead{\textbf{\Large Homework \asgnname}}
\rhead{\today}
\headsep 10pt

\begin{document}

\begin{answer}{5.24}
A friend wants to use our bloom filter of size $m = 2^b$ bits but only has $2^{b-1}$ bits available. Instead of recreating a bloom filter from scratch, our friend could instead use ours with a view minor alterations. Call $A$ the original filter, and $B$ the friends filter. We can trivially make $B$ equal to the first $2^{b-1}$ bits of $A$, but that leaves $2^{b-1}$ bits left to map. The solution is to assume that each $h_i(x)$ hash function instead is returning its output mod $2^{b-1}$ instead of $2^b$, so we can bitwise OR the first $2^{b-1}$ bits of $A$ with the second to form $B$. Then, it suffices to alter each hash function accordingly.
\end{answer}

\begin{answer}{6.3}
Given an $n$-vertex undirected graph $G = (V, E)$, we construct an independent set using the following algorithm.
\begin{itemize}
	\item Give an permutation $\sigma$ of the vertices, define a subset $S(\sigma)$ of the vertices as follows.
	\item For each vertex $i, i\in S(\sigma)$ if and only if no neighbor $j$ of $i$ precedes $i$ in the permutation $\sigma$
\end{itemize}
\begin{enumerate}[(a)]
	\item Claim: $S(\sigma)$ is an independent set. We will prove by contradiction. Assume that $S(\sigma)$ is not an indepenent set. Then there exist two vertices $x$ and $y$ that are neighbors and are in $S(\sigma)$. There are two cases.
		\begin{itemize}
			\item $x$ precedes $y$ in $\sigma$. Then we would never have added $y$ via the algorithm
			\item $y$ precedes $x$ in $\sigma$. Then we would never have added $x$ via the algorithm
		\end{itemize}
		Thus a non-independent set is impossible by following this algorithm.
	\item Let $X$ be the cardinality of $S$. We want
		$$ E[X] = \sum_{i=1}^n \frac{1}{d_i + 1}$$
		Where $d_i$ denotes the degree of vertex $i$. Let $\sigma$ be defined as a random permutation, generated by an algorithm like the Knuth shuffle. This algorithm will return a given permutation of the vertices exactly $\frac{1}{n!}$ of the time.\\

		Let $X_i$ be a random variable that is 1 if the $i$th vertex is in $S$ and 0 otherwise. Then clearly $X = \sum_{i} X_i$. The probability the $i$th vertex is in $S$ is exactly the probability that the $i$th vertex is \emph{first} out of all its $d_i$ neighbors in $\sigma$. By our random permutation, it is clear that
		$$E[X_i] = 1 * Pr(X_i = 1) = \frac{d_i!}{(1 + d_i)!} = \frac{1}{1 + d_i}$$
		This is precisely what we are looking for, because
		$$E[X] = E[\sum_{i=1}^n X_i] = \sum_{i=1}^n E[X_i] = \sum_{i=1}^n \frac{1}{1 + d_i}$$

	\item Claim: $G$ has an independent set of size at least $\omega = \sum_{i=1}^n \frac{1}{1 + d_i}$. This follows directly from (b) and Lemma 6.2: that if $E[X] = \mu$, then $Pr(X \ge \mu) > 0$. So we know that $Pr(X \ge \omega) > 0$, which means there exists at least one subset $S$ with cardinality $\omega$ which we proved is an independent set of $G$.

\end{enumerate}
\end{answer}

\begin{answer}{6.6}
Claim: Any graph with $m$ edges has a $k$-cut with value at least $\frac{m(k-1)}{k}$.\\
Proof: We will generalize Theorem 6.3. Construct subsets $S_1,\S_2,\ldots,S_k$ from $G$ by randomly and independently assigning vertices to one of the $k$ sets. Let $e_1,\ldots,e_m$ be an arbitrary enumeration of the edges of $G$. For $i = 1,\ldots,m$, define
$$
	X_i = \begin{cases}
	1 &\mbox{ if edge $i$ connects $S_a$ to $S_b$, $a \ne b$}\\
	0 &\mbox{ otherwise}
	\end{cases}
$$
The probability that a random edge connects two different subsets $S_a$ and $S_b$ is $1 - \frac{1}{k}$, so

	$$E[X_i] = \frac{k - 1}{k}$$
If $X$ is the random variable denoting the value of the cut corresponding to the sets $S_1$ through $S_k$, then
	$$E[X] = E[\sum_{i=1}^m X_i] = \sum_{i=1}^m E[X_i] = \frac{m(k-1)}{k}$$

Because the expectation of the random variable $X$ is $\frac{m(k-1)}{k}$, then there exists a partition $S_1$ through $S_k$ with at least $\frac{m(k-1)}{k}$ edges connecting the sets to each other. \\

We can transform this argument into an algorithm for \emph{finding} such a cut using derandomization and conditional expectation. Suppose we partition verticesin a completely deterministic way into $k$ subsets in any arbitrary order $v_1,\ldots, v_n$. Let $s_i$ be the set where $v_i$ is placed. Suppose we have placed exactly $t$ vertices. Then the expected value of the cut is
	$$E[X | s_1,s_2,\ldots,s_t]$$
Given the locations of the first $t$ vertices, we will show inductively how to place the next vertex.\\
Claim: $E[X | s_1,s_2,\ldots,s_t] \le E[X | s_1,\ldots,s_{t+1}]$
\begin{itemize}
	\item Base case: $E[X | s_1] = E[X]$. This is trivially true because it will never matter where we place the first vertex.
	\item Inductive step: Assume that $E[X | s_1,\ldots,s_{p-1}] \le E[X | s_1,\ldots,s_{p}$ for some $p$. Now consider placing the $v_{p+1}$ randomly into one of the $k$ sets with probability $\frac{1}{k}$ each. Assign the random variable $Y_{p+1}$ representing the set where it is placed. Then

	$$E[X | s_1,\ldots,s_p] = \sum_{j=1}^k \frac{1}{k}E[X | s_1,\ldots,s_p,Y_{p+1} = S_j]$$

	It follows that
	$$max(E[X | s_1,\ldots, s_p, Y_{p+1}=S_1], \ldots, E[X | s_1,\ldots, s_p, Y_{p+1} = S_k]) \ge E[X | s_1,\ldots, s_p]$$

	Therefore we just need to compute $k$ quantities, and place $v_{p+1}$ in the set that yields the maximum expectation. Once we do this, we will have satisfied our claim. To compute $E[X | s_1, \ldots, s_p, Y_{p+1} = S_j]$, note the conditioning gives us the placement of the first $p+1$ vertices. We can therefore compute the number of edges among these vertices that contribute to the value of the cut. For all other edges, the probability that it will later contribute to the cut is $\frac{k-1}{k}$, since this is the probability that its two endpoints end up in different sets. Thus $E[X | s_1, \ldots, s_p, Y_{p+1} = S_j]$ is the number of edges crossing the cut whose endpoints are both among the first $p + 1$ vertices, plus $\frac{k-1}{k}$ of the remaining edges. This is easy to compute in linear time, and holds for $1 \le j \le k$.\\

	Thus, the largest of the $k$ quantities is determined just by whether $v_{p+1}$ has more neighbors in $S_1$ through $S_k$. All edges that do not have $v_{p+1}$ as an endpoint contribute the same amount to the $k$ expectations. This finishes the inductive argument, and we have shown that we can always place another vertex without decreasing our expected cut value.\\

	Thus our derandomized algorithm is the following: take the vertices in some order. Place the first vertex arbitrarily in $S_1$. Place each successive vertex to maximize the number of edges crossing the cut. That is, place each vertex on the side with fewer neighbors, breaking ties arbitrarily. This always guarantees a cut with at least $\frac{m(k-1)}{k}$ edges.
\end{itemize}
\end{answer}

\end{document}

